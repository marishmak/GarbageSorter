{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "!pip install telebot torch torchvision\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "FtFWMBbri6oa"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLpUy6j6hudi",
        "outputId": "20b30399-6c54-4363-dfed-94ebd3528b17"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp drive/'My Drive'/ViT_B_16_weights.pth ."
      ],
      "metadata": {
        "id": "q59Zc3LViBD8"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tempfile\n",
        "import cv2\n",
        "import telebot\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import vit_b_16, ViT_B_16_Weights"
      ],
      "metadata": {
        "id": "aqhI24wyi2Bw"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2label={0:'battery', 1: 'biological', 2:'brown-glass', 3:'cardboard', 4:'green-glass', 5:'metal', 6:'paper', 7:'plastic', 8:'trash', 9:'white-glass'}"
      ],
      "metadata": {
        "id": "Y30AvhyxlXwY"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "num_classes = 10  # Replace with your actual number of classes\n",
        "\n",
        "# Load the pre-trained Vision Transformer model\n",
        "model = vit_b_16(weights=ViT_B_16_Weights.DEFAULT)\n",
        "model.heads.head = torch.nn.Linear(model.heads.head.in_features, num_classes)\n",
        "\n",
        "# Load the state dictionary into the model\n",
        "model_path = 'ViT_B_16_weights.pth'\n",
        "state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
        "model.load_state_dict(state_dict)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "b-4sFl2uhJWt"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def garbage_class_recognition(image):\n",
        "    with torch.no_grad():\n",
        "        # Perform the forward pass\n",
        "        outputs = model(image)\n",
        "        # Get the predicted class index\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "    return predicted.item()"
      ],
      "metadata": {
        "id": "i3HLUeJpiAqb"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "v6ir7zadgdk0"
      },
      "outputs": [],
      "source": [
        "# link: https://t.me/Garbage_Classifier_bot\n",
        "\n",
        "API_TOKEN = '7209626391:AAGTcSQ0hSPI_m90FKvg7wgX_QYJPkZBydg'\n",
        "bot = telebot.TeleBot(API_TOKEN)\n",
        "\n",
        "@bot.message_handler(commands=['start'])\n",
        "def send_welcome(message):\n",
        "    bot.reply_to(message, \"Hi, I'm a bot assistant in sorting garbage! Send me an image of a separate item of garbage and I will tell you which class of waste it belongs to.\")\n",
        "\n",
        "@bot.message_handler(content_types=['photo'])\n",
        "def handle_image(message):\n",
        "\n",
        "    file_id = message.photo[-1].file_id\n",
        "    file_info = bot.get_file(file_id)\n",
        "    downloaded_file = bot.download_file(file_info.file_path)\n",
        "\n",
        "    with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as temp_file:\n",
        "        temp_file.write(downloaded_file)\n",
        "        temp_file_path = temp_file.name\n",
        "\n",
        "    image = cv2.imread(temp_file_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = Image.fromarray(image)\n",
        "\n",
        "    image = transform(image).unsqueeze(0)\n",
        "\n",
        "    category = garbage_class_recognition(image)\n",
        "    name=id2label[int(category)]\n",
        "\n",
        "    bot.reply_to(message, f'Recognized category:\\n{name}')\n",
        "\n",
        "    os.remove(temp_file_path)\n",
        "\n",
        "bot.polling()"
      ]
    }
  ]
}